{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFS 505 Spring 2020, Unit 2 Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Background\n",
    "\n",
    "This project will cover all aspects of the Data Analytics with Python unit.  To complete the project, follow the instructions at each step in the notebook and add Python code or written explanations as instructed.   Some tasks below will require you to answer with a written response rather than writing code.  Those tasks begin with the words \"Explain\" or \"Write\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due Dates\n",
    "\n",
    "This project requires knoweldge gained throughout the unit. However, waiting until the end of the 5-week unit make this project overwhelming.  Instead, as we cover the material required for different sections you are required to check-in the project. This ensures continued progress througout the 5 weeks.  \n",
    "\n",
    "Project Check-in dates are \n",
    "- Tuesday March 3, Sections 1-3\n",
    "- Tuesday March 10, Section 4\n",
    "- Tuesday March 24, Sections 5-6\n",
    "- Tuesday March 28, Sections 7-8\n",
    "\n",
    "The full Project is due March 28th (same day as the last check-in)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How to turn in \n",
    "***DO NOT*** sumbit this poject to your GitHub repository.  Instead you will need to submit your completed Jupyter notebook directly to Dr. Ficklin via Slack for each check-in. The notebook should be saved, fully populated with results and images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grading\n",
    "Submission of the project on the check-in dates with each section fully completed yeilds 5 points per check-in on your final grade. The prescribed sections must be fully completed, but they need not be correct except at the last check-in on March 28th.  \n",
    "\n",
    "The final grade for this project sums to 200 points and is worth 30% of your overall class grade. The amount that each section contributes is indicated on each of the tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Introducution\n",
    "\n",
    "To complete this project you will need to retrieve the \"Cover Type Dataset\" available at the UC Irvine Machine Learning Repository. You can find information about the dataset as well as the data [here](https://archive.ics.uci.edu/ml/datasets/Covertype).  To download the data, click the link at the top that reads **Data Folder**.  On the resulting page you will find three files for download.  Please download the file named `covtype.data.gz`, and use your preferred decompression utility to uncompress the file.  \n",
    "\n",
    "Before you can begin with this project, you must familarize yourself with the data.  Please read the `convtype.info` file that is also available for download.  You can either download the file and open with your favorite text editor or [view it in the web browser](https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info).\n",
    "\n",
    "In Summary:\n",
    "\n",
    "> Natural resource managers responsible for developing ecosystem management strategies require basic descriptive information including inventory data for forested lands to support their decision-making processes.  However, managers generally do not have this type of data for inholdings or neighboring lands that are outside their immediate jurisdiction.  **One method of obtaining this information is through the use of predictive models.**  \n",
    "\n",
    "> [The purpose of this dataset is for] predicting forest cover type from cartographic variables... The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data... Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). \n",
    "\n",
    "\n",
    "\n",
    "Here are some hints to help explain some of the data columns:\n",
    "\n",
    "- Slope:  The angle in degrees of the slope on which the forest cover is growing.  \n",
    "- Aspect:  The direction the slope is facing in degrees azimuth:  North = 0, East = 90, South = 180, West = 270.\n",
    "- The columns representing shade contain values from 0 to 255 with 0 meaning no sun and 255 meaning full sun.\n",
    "- There are 40 columns representing differnet soil types.  See the `convtype.info` file for a listing of these types.  The observations in these 40 columns indicate if cover was: absent = 0, present = 1\n",
    "- There are 4 columns representing 4 different wilderness areas. The observations in these 4 columns indicate if cover was:  absent = 0, present = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "For this project you will utilize Numpy, Pandas, Matplotlib, Seaborn and Sklearn to create a Supervised Machine learning model that can assist natural resouce managers predict tree cover in neighboring lands.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tips\n",
    "1. If you feel that your solution in a cell is too complicated, it probably is.  Check the online documentation and expect there may be shortcuts to do what you want.\n",
    "2. If you encounter Memory Error or the notebook seems to not execute, you may need to restart the Kernel and re-run the cells.\n",
    "3. Please contact the instructor if you have questions about this project.  You may ask any question you want!\n",
    "4. Before turning in your notebook carefully re-read each step to ensure you've followed it correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Academic Honesty\n",
    "You must work on your own to complete this project.  You should not work on this project together with other students. If you have questions please ask the instructurs or post them to the Slack channel where every student can see your question and benefit from any answers. You may consult the notebooks provided to you for the class or the online documentation for any of the tools (e.g. Numpy, Pandas, Seaborn, or Sklearn), but do not use online tutorials, or question/answer forums for solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup the Notebook\n",
    "**1a.** Load all the necessary packages and libraries required for the entire notebook using the following (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Import the data\n",
    "**2a.** First, import the data. Note, it does not have any headers. This is a large dataset so it may  take a minute to load (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581006</td>\n",
       "      <td>2396.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581007</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581008</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581009</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581010</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581011 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2596     51     3    258      0     510    221    232    148  \\\n",
       "0       2590.0   56.0   2.0  212.0   -6.0   390.0  220.0  235.0  151.0   \n",
       "1       2804.0  139.0   9.0  268.0   65.0  3180.0  234.0  238.0  135.0   \n",
       "2       2785.0  155.0  18.0  242.0  118.0  3090.0  238.0  238.0  122.0   \n",
       "3       2595.0   45.0   2.0  153.0   -1.0   391.0  220.0  234.0  150.0   \n",
       "4       2579.0  132.0   6.0  300.0  -15.0    67.0  230.0  237.0  140.0   \n",
       "...        ...    ...   ...    ...    ...     ...    ...    ...    ...   \n",
       "581006  2396.0  153.0  20.0   85.0   17.0   108.0  240.0  237.0  118.0   \n",
       "581007  2391.0  152.0  19.0   67.0   12.0    95.0  240.0  237.0  119.0   \n",
       "581008  2386.0  159.0  17.0   60.0    7.0    90.0  236.0  241.0  130.0   \n",
       "581009  2384.0  170.0  15.0   60.0    5.0    90.0  230.0  245.0  143.0   \n",
       "581010  2383.0  165.0  13.0   60.0    4.0    67.0  231.0  244.0  141.0   \n",
       "\n",
       "          6279  ...  0.34  0.35  0.36  0.37  0.38  0.39  0.40  0.41  0.42    5  \n",
       "0       6225.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "1       6121.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "2       6211.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "3       6172.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "4       6031.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "...        ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  \n",
       "581006   837.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  3.0  \n",
       "581007   845.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  3.0  \n",
       "581008   854.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  3.0  \n",
       "581009   864.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  3.0  \n",
       "581010   875.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  3.0  \n",
       "\n",
       "[581011 rows x 55 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df = pd.read_csv('covtype.data.gz', header = 0 ,compression = 'gzip', dtype = float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Display the first 10 lines of the data (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2605.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>6244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2596     51     3    258      0     510    221    232    148    6279  \\\n",
       "0  2590.0   56.0   2.0  212.0   -6.0   390.0  220.0  235.0  151.0  6225.0   \n",
       "1  2804.0  139.0   9.0  268.0   65.0  3180.0  234.0  238.0  135.0  6121.0   \n",
       "2  2785.0  155.0  18.0  242.0  118.0  3090.0  238.0  238.0  122.0  6211.0   \n",
       "3  2595.0   45.0   2.0  153.0   -1.0   391.0  220.0  234.0  150.0  6172.0   \n",
       "4  2579.0  132.0   6.0  300.0  -15.0    67.0  230.0  237.0  140.0  6031.0   \n",
       "5  2606.0   45.0   7.0  270.0    5.0   633.0  222.0  225.0  138.0  6256.0   \n",
       "6  2605.0   49.0   4.0  234.0    7.0   573.0  222.0  230.0  144.0  6228.0   \n",
       "7  2617.0   45.0   9.0  240.0   56.0   666.0  223.0  221.0  133.0  6244.0   \n",
       "8  2612.0   59.0  10.0  247.0   11.0   636.0  228.0  219.0  124.0  6230.0   \n",
       "9  2612.0  201.0   4.0  180.0   51.0   735.0  218.0  243.0  161.0  6222.0   \n",
       "\n",
       "   ...  0.34  0.35  0.36  0.37  0.38  0.39  0.40  0.41  0.42    5  \n",
       "0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "2  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "3  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  2.0  \n",
       "5  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "6  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "7  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "8  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "9  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  5.0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** Add appropriate headers to the data frame, using the following array:\n",
    "\n",
    "```python\n",
    "headers = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', \n",
    "           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', \n",
    "           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "           'Rawah', 'Neota', 'Comanche_Peak', 'Cache_la_Poudre', \n",
    "           'ST1', 'ST2', 'ST3', 'ST4', 'ST5', 'ST6', 'ST7', 'ST8', 'ST9', 'ST10',\n",
    "           'ST11', 'ST12', 'ST13', 'ST14', 'ST15', 'ST16', 'ST17', 'ST18', 'ST19', 'ST20',\n",
    "           'ST21', 'ST22', 'ST23', 'ST24', 'ST25', 'ST26', 'ST27', 'ST28', 'ST29', 'ST30',\n",
    "           'ST31', 'ST32', 'ST33', 'ST34', 'ST35', 'ST36', 'ST37', 'ST38', 'ST39', 'ST40',\n",
    "           'Cover_Type'\n",
    "           \n",
    "]\n",
    "```\n",
    "(3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>ST32</th>\n",
       "      <th>ST33</th>\n",
       "      <th>ST34</th>\n",
       "      <th>ST35</th>\n",
       "      <th>ST36</th>\n",
       "      <th>ST37</th>\n",
       "      <th>ST38</th>\n",
       "      <th>ST39</th>\n",
       "      <th>ST40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581007</td>\n",
       "      <td>2396</td>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>118</td>\n",
       "      <td>837</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581008</td>\n",
       "      <td>2391</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>119</td>\n",
       "      <td>845</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581009</td>\n",
       "      <td>2386</td>\n",
       "      <td>159</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>236</td>\n",
       "      <td>241</td>\n",
       "      <td>130</td>\n",
       "      <td>854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581010</td>\n",
       "      <td>2384</td>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>230</td>\n",
       "      <td>245</td>\n",
       "      <td>143</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581011</td>\n",
       "      <td>2383</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>231</td>\n",
       "      <td>244</td>\n",
       "      <td>141</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581012 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0            2596      51      3                               258   \n",
       "1            2590      56      2                               212   \n",
       "2            2804     139      9                               268   \n",
       "3            2785     155     18                               242   \n",
       "4            2595      45      2                               153   \n",
       "...           ...     ...    ...                               ...   \n",
       "581007       2396     153     20                                85   \n",
       "581008       2391     152     19                                67   \n",
       "581009       2386     159     17                                60   \n",
       "581010       2384     170     15                                60   \n",
       "581011       2383     165     13                                60   \n",
       "\n",
       "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                    0                              510   \n",
       "1                                   -6                              390   \n",
       "2                                   65                             3180   \n",
       "3                                  118                             3090   \n",
       "4                                   -1                              391   \n",
       "...                                ...                              ...   \n",
       "581007                              17                              108   \n",
       "581008                              12                               95   \n",
       "581009                               7                               90   \n",
       "581010                               5                               90   \n",
       "581011                               4                               67   \n",
       "\n",
       "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                 221             232            148   \n",
       "1                 220             235            151   \n",
       "2                 234             238            135   \n",
       "3                 238             238            122   \n",
       "4                 220             234            150   \n",
       "...               ...             ...            ...   \n",
       "581007            240             237            118   \n",
       "581008            240             237            119   \n",
       "581009            236             241            130   \n",
       "581010            230             245            143   \n",
       "581011            231             244            141   \n",
       "\n",
       "        Horizontal_Distance_To_Fire_Points  ...  ST32  ST33  ST34  ST35  ST36  \\\n",
       "0                                     6279  ...     0     0     0     0     0   \n",
       "1                                     6225  ...     0     0     0     0     0   \n",
       "2                                     6121  ...     0     0     0     0     0   \n",
       "3                                     6211  ...     0     0     0     0     0   \n",
       "4                                     6172  ...     0     0     0     0     0   \n",
       "...                                    ...  ...   ...   ...   ...   ...   ...   \n",
       "581007                                 837  ...     0     0     0     0     0   \n",
       "581008                                 845  ...     0     0     0     0     0   \n",
       "581009                                 854  ...     0     0     0     0     0   \n",
       "581010                                 864  ...     0     0     0     0     0   \n",
       "581011                                 875  ...     0     0     0     0     0   \n",
       "\n",
       "        ST37  ST38  ST39  ST40  Cover_Type  \n",
       "0          0     0     0     0           5  \n",
       "1          0     0     0     0           5  \n",
       "2          0     0     0     0           2  \n",
       "3          0     0     0     0           2  \n",
       "4          0     0     0     0           5  \n",
       "...      ...   ...   ...   ...         ...  \n",
       "581007     0     0     0     0           3  \n",
       "581008     0     0     0     0           3  \n",
       "581009     0     0     0     0           3  \n",
       "581010     0     0     0     0           3  \n",
       "581011     0     0     0     0           3  \n",
       "\n",
       "[581012 rows x 55 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', \n",
    "           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', \n",
    "           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "           'Rawah', 'Neota', 'Comanche_Peak', 'Cache_la_Poudre', \n",
    "           'ST1', 'ST2', 'ST3', 'ST4', 'ST5', 'ST6', 'ST7', 'ST8', 'ST9', 'ST10',\n",
    "           'ST11', 'ST12', 'ST13', 'ST14', 'ST15', 'ST16', 'ST17', 'ST18', 'ST19', 'ST20',\n",
    "           'ST21', 'ST22', 'ST23', 'ST24', 'ST25', 'ST26', 'ST27', 'ST28', 'ST29', 'ST30',\n",
    "           'ST31', 'ST32', 'ST33', 'ST34', 'ST35', 'ST36', 'ST37', 'ST38', 'ST39', 'ST40',\n",
    "           'Cover_Type'\n",
    "\n",
    "]\n",
    "project_df = pd.read_csv('covtype.data.gz', names = headers, compression = 'gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d.** Display the first 10 lines of data again to confirm the headers are present (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>ST32</th>\n",
       "      <th>ST33</th>\n",
       "      <th>ST34</th>\n",
       "      <th>ST35</th>\n",
       "      <th>ST36</th>\n",
       "      <th>ST37</th>\n",
       "      <th>ST38</th>\n",
       "      <th>ST39</th>\n",
       "      <th>ST40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2606</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>270</td>\n",
       "      <td>5</td>\n",
       "      <td>633</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>138</td>\n",
       "      <td>6256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2605</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>7</td>\n",
       "      <td>573</td>\n",
       "      <td>222</td>\n",
       "      <td>230</td>\n",
       "      <td>144</td>\n",
       "      <td>6228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2617</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>240</td>\n",
       "      <td>56</td>\n",
       "      <td>666</td>\n",
       "      <td>223</td>\n",
       "      <td>221</td>\n",
       "      <td>133</td>\n",
       "      <td>6244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2612</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>11</td>\n",
       "      <td>636</td>\n",
       "      <td>228</td>\n",
       "      <td>219</td>\n",
       "      <td>124</td>\n",
       "      <td>6230</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "5       2579     132      6                               300   \n",
       "6       2606      45      7                               270   \n",
       "7       2605      49      4                               234   \n",
       "8       2617      45      9                               240   \n",
       "9       2612      59     10                               247   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "5                             -15                               67   \n",
       "6                               5                              633   \n",
       "7                               7                              573   \n",
       "8                              56                              666   \n",
       "9                              11                              636   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "5            230             237            140   \n",
       "6            222             225            138   \n",
       "7            222             230            144   \n",
       "8            223             221            133   \n",
       "9            228             219            124   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  ST32  ST33  ST34  ST35  ST36  \\\n",
       "0                                6279  ...     0     0     0     0     0   \n",
       "1                                6225  ...     0     0     0     0     0   \n",
       "2                                6121  ...     0     0     0     0     0   \n",
       "3                                6211  ...     0     0     0     0     0   \n",
       "4                                6172  ...     0     0     0     0     0   \n",
       "5                                6031  ...     0     0     0     0     0   \n",
       "6                                6256  ...     0     0     0     0     0   \n",
       "7                                6228  ...     0     0     0     0     0   \n",
       "8                                6244  ...     0     0     0     0     0   \n",
       "9                                6230  ...     0     0     0     0     0   \n",
       "\n",
       "   ST37  ST38  ST39  ST40  Cover_Type  \n",
       "0     0     0     0     0           5  \n",
       "1     0     0     0     0           5  \n",
       "2     0     0     0     0           2  \n",
       "3     0     0     0     0           2  \n",
       "4     0     0     0     0           5  \n",
       "5     0     0     0     0           2  \n",
       "6     0     0     0     0           5  \n",
       "7     0     0     0     0           5  \n",
       "8     0     0     0     0           5  \n",
       "9     0     0     0     0           5  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Explore the Data\n",
    "**3a.** Show the dimensions of the data (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 55)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Show the datatypes of all of the columns in the data (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             int64\n",
       "Aspect                                int64\n",
       "Slope                                 int64\n",
       "Horizontal_Distance_To_Hydrology      int64\n",
       "Vertical_Distance_To_Hydrology        int64\n",
       "Horizontal_Distance_To_Roadways       int64\n",
       "Hillshade_9am                         int64\n",
       "Hillshade_Noon                        int64\n",
       "Hillshade_3pm                         int64\n",
       "Horizontal_Distance_To_Fire_Points    int64\n",
       "Rawah                                 int64\n",
       "Neota                                 int64\n",
       "Comanche_Peak                         int64\n",
       "Cache_la_Poudre                       int64\n",
       "ST1                                   int64\n",
       "ST2                                   int64\n",
       "ST3                                   int64\n",
       "ST4                                   int64\n",
       "ST5                                   int64\n",
       "ST6                                   int64\n",
       "ST7                                   int64\n",
       "ST8                                   int64\n",
       "ST9                                   int64\n",
       "ST10                                  int64\n",
       "ST11                                  int64\n",
       "ST12                                  int64\n",
       "ST13                                  int64\n",
       "ST14                                  int64\n",
       "ST15                                  int64\n",
       "ST16                                  int64\n",
       "ST17                                  int64\n",
       "ST18                                  int64\n",
       "ST19                                  int64\n",
       "ST20                                  int64\n",
       "ST21                                  int64\n",
       "ST22                                  int64\n",
       "ST23                                  int64\n",
       "ST24                                  int64\n",
       "ST25                                  int64\n",
       "ST26                                  int64\n",
       "ST27                                  int64\n",
       "ST28                                  int64\n",
       "ST29                                  int64\n",
       "ST30                                  int64\n",
       "ST31                                  int64\n",
       "ST32                                  int64\n",
       "ST33                                  int64\n",
       "ST34                                  int64\n",
       "ST35                                  int64\n",
       "ST36                                  int64\n",
       "ST37                                  int64\n",
       "ST38                                  int64\n",
       "ST39                                  int64\n",
       "ST40                                  int64\n",
       "Cover_Type                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c.** Show if the dataset has any missing values (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             0\n",
       "Aspect                                0\n",
       "Slope                                 0\n",
       "Horizontal_Distance_To_Hydrology      0\n",
       "Vertical_Distance_To_Hydrology        0\n",
       "Horizontal_Distance_To_Roadways       0\n",
       "Hillshade_9am                         0\n",
       "Hillshade_Noon                        0\n",
       "Hillshade_3pm                         0\n",
       "Horizontal_Distance_To_Fire_Points    0\n",
       "Rawah                                 0\n",
       "Neota                                 0\n",
       "Comanche_Peak                         0\n",
       "Cache_la_Poudre                       0\n",
       "ST1                                   0\n",
       "ST2                                   0\n",
       "ST3                                   0\n",
       "ST4                                   0\n",
       "ST5                                   0\n",
       "ST6                                   0\n",
       "ST7                                   0\n",
       "ST8                                   0\n",
       "ST9                                   0\n",
       "ST10                                  0\n",
       "ST11                                  0\n",
       "ST12                                  0\n",
       "ST13                                  0\n",
       "ST14                                  0\n",
       "ST15                                  0\n",
       "ST16                                  0\n",
       "ST17                                  0\n",
       "ST18                                  0\n",
       "ST19                                  0\n",
       "ST20                                  0\n",
       "ST21                                  0\n",
       "ST22                                  0\n",
       "ST23                                  0\n",
       "ST24                                  0\n",
       "ST25                                  0\n",
       "ST26                                  0\n",
       "ST27                                  0\n",
       "ST28                                  0\n",
       "ST29                                  0\n",
       "ST30                                  0\n",
       "ST31                                  0\n",
       "ST32                                  0\n",
       "ST33                                  0\n",
       "ST34                                  0\n",
       "ST35                                  0\n",
       "ST36                                  0\n",
       "ST37                                  0\n",
       "ST38                                  0\n",
       "ST39                                  0\n",
       "ST40                                  0\n",
       "Cover_Type                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d.** Show how many rows of data are duplicated (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3e.** Show how many unique values there are per column (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             1978\n",
       "Aspect                                 361\n",
       "Slope                                   67\n",
       "Horizontal_Distance_To_Hydrology       551\n",
       "Vertical_Distance_To_Hydrology         700\n",
       "Horizontal_Distance_To_Roadways       5785\n",
       "Hillshade_9am                          207\n",
       "Hillshade_Noon                         185\n",
       "Hillshade_3pm                          255\n",
       "Horizontal_Distance_To_Fire_Points    5827\n",
       "Rawah                                    2\n",
       "Neota                                    2\n",
       "Comanche_Peak                            2\n",
       "Cache_la_Poudre                          2\n",
       "ST1                                      2\n",
       "ST2                                      2\n",
       "ST3                                      2\n",
       "ST4                                      2\n",
       "ST5                                      2\n",
       "ST6                                      2\n",
       "ST7                                      2\n",
       "ST8                                      2\n",
       "ST9                                      2\n",
       "ST10                                     2\n",
       "ST11                                     2\n",
       "ST12                                     2\n",
       "ST13                                     2\n",
       "ST14                                     2\n",
       "ST15                                     2\n",
       "ST16                                     2\n",
       "ST17                                     2\n",
       "ST18                                     2\n",
       "ST19                                     2\n",
       "ST20                                     2\n",
       "ST21                                     2\n",
       "ST22                                     2\n",
       "ST23                                     2\n",
       "ST24                                     2\n",
       "ST25                                     2\n",
       "ST26                                     2\n",
       "ST27                                     2\n",
       "ST28                                     2\n",
       "ST29                                     2\n",
       "ST30                                     2\n",
       "ST31                                     2\n",
       "ST32                                     2\n",
       "ST33                                     2\n",
       "ST34                                     2\n",
       "ST35                                     2\n",
       "ST36                                     2\n",
       "ST37                                     2\n",
       "ST38                                     2\n",
       "ST39                                     2\n",
       "ST40                                     2\n",
       "Cover_Type                               7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Clean the Data\n",
    "### 4.1. Missing Values\n",
    "**4a.** If the dataset had missing values, determine if you need to clean the data. If so, show the code below. If you do not perform any cleaning indicate why (change the cell to \"raw\" type to write your explanation)  (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Duplicated Data\n",
    "**4b.** If the dataset had duplicated values, determine if you need to clean the data. If so, show the code below. If not, describe the status of duplicated data in this dataset (change the cell to \"raw\" type to write your explanation)  (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b.** Explain if the unique number of values or each of the categorical columns (non numeric and non binary) match what is expected based on the description of the data  (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Fix Categorical Data\n",
    "Some of the columns are categorical (i.e. qualitative).  Remember, just becauase a column contains numbers does not mean it is quantitative. In the online description of the data, the authors stated that the soil types and wilderness areas are qualitative (categorical). You must decide if this is true given the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Write the names of the columns that are categorical (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e.** Change all categorical columns that were imported as a numeric type to a string type  (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** Confirm that all categorical columns are no longer numeric (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e.** The `Cover_Type` column is a string but appears numeric, and each number represents a unique class of trees. Convert the numeric values to their corresponding string representations. Print the top 10 entries to confirm your replacement worked (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Subset the Data\n",
    "The dataset is a bit large for this notebook. It will consume too much RAM on your computer.  If we were executing this on a computer with more RAM we might just write a Python script to do the work rather than use a Jupyter notebook.  To reduce the dataset we should subset our data to save resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4f.** Before we subset the data, let's explore the number of samples per cover type.  For the `Cover_type` column, show the counts of each type of cover, and sort the results from largest to smallest (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4g.**  The results of the previous cell show that the number of measurements per cover type is imbalanced with the smallest having 2,747 observations and the largest 283,301.  Let's subset the data to only include 2,000 randomly selected samples from each cover type.   We have not covered in class how to do this, so below is a code sample you can use. \n",
    "```python\n",
    "df = df.groupby(by=\"Cover_Type\").apply(lambda x : x.sample(2000)).reset_index(drop=True)\n",
    "```\n",
    "Notice in the line of code above, we first perform a `groupby` operation to organize rows by their cover type. Next, we  call `apply` on each group. With the `apply` function you must provide the name of the function that will be called for each group. In this case, the word `lambda` tells python that we are declaring an \"anonymous\" in-line function (no `def` line) that takes an argument `x`.  As the apply is executed on each group, the variable `x` contains the data for each group, and is actually a Pandas DataFrame. Hence, we can call `sample` to select 2000 random rows.  The `apply` function returns a new DataFrame containing all selected rows from all groups.  On this data frame we call `reset_index` to renumber the index for all of our rows.\n",
    "\n",
    "(3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4h.** Re-run the same command from task 4f. The results should show an even 2,000 samples of each cover type (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Tidy or not to Tidy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this dataset is not tidy!  We have a variable in the headers:  the different soil types.  To tidy this data we would normally melt the soil types into a single column, perhaps named `Soil_Type`. We could then remove all rows where the soil type was not present (i.e. has a value of 0) and drop the melted values column with the absent/present binary value.  \n",
    "\n",
    "However, as we've learned in class, the Sklearn package which we will use for machine learning cannot handle strings for categorical data.  It wants categorical data reset as numeric values: one for each category. But this only works for ordinal data.  Our soil type data is not ordinal.  If we melted our dataframe, then for machine learning we would need to perform [\"One Hot Encoding\"](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) to put the `Soil_Type` column dataframe into a format that Sklearn approves of. The end result is a pivot of the dataframe back to what it currently is!  So, even though we should Tidy this dataset, let's leave it as is for Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Understand the data\n",
    "### 5.1  Review Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5a.** Generate a dataframe that contains the number of times we see a soil type present for each cover type.  Show the top 10 rows of the dataframe.\n",
    "\n",
    "For example:\n",
    "\n",
    "<table>\n",
    "    <tr><th></th><th>Cover_Type</th><th>Soil_Type</th><th>Present</th></tr>\n",
    "    <tr><th>0</th><th>Aspen</th><th>ST02</th><th>53</th></tr>\n",
    "    <tr><th>1</th><th>Aspen</th><th>ST04</th><th>117</th></tr>\n",
    "    <tr><th>2</th><th>Aspen</th><th>ST10</th><th>64</th></tr>\n",
    "    <tr><th>3</th><th>Aspen</th><th>ST11</th><th>148</th></tr>\n",
    "    <tr><th>4</th><th>Aspen</th><th>ST13</th><th>319</th></tr>\n",
    "</table>\n",
    "\n",
    "Hint:\n",
    "- Start with a reduced dataframe that only contains the 40 soil types + `Cover_Type`\n",
    "- Melt the data.\n",
    "- Exclude soil types that are absent.\n",
    "- Use a `groupby`.\n",
    "\n",
    "(5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b.** Using the dataframe just created, draw a plot showing the relationship between the cover type and the soil type. Size the points in the plot by the counts. Ensure that the axis ticks and legend are legible. Save the figure to a file named `covtype-soil_type.scatter.png` for viewing (5 pts). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c.** Explain why it is important to review the scatterplot of \"Cover_Type\" vs. all the soil types (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review the quantitative data\n",
    "**5d.** Show the basic summary statistics for the quantitiatve data, excluding the 40 binary soil type columns (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5e.** Use the [hist](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html) function of Pandas Dataframes to create a single figure showing the histograms of every quantitative data column excluding the 40 binary soil type columns.  Size the figure to ensure all text is legible. Save the figure to a file named `covtype.histograms.png` for viewing. \n",
    "\n",
    "Hint:\n",
    "- Because you will use the `DataFrame.hist` function you aren't calling matplotlib or Seaborn functions directly.  Therefore, use the `plt.savefig` function. Remember, the `plt` object always maintains the current figure, so you can use it to call the `savefig` function.\n",
    "\n",
    "(5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5f.** Explain why it is important to examine the histogram of each quantitative column (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5g.** Use the Seaborn [sns.pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html) function to gererate a scatterplot of every quantitative column (excluding the 40 binary soil type columns) with every other quantitative column.  Use `Cover_Type` as the `hue` argument, use `\"kde\"` as the `diag_kind` argument, and use `5` as the `height` argument.  Because each scatterplot will be small we need to limit the size and number of points. Otherwise, the points overlap which and will hide the color of those behind.  Include only 1000 randomly selected rows from the dataset.  To further improve the plot we can set the size of the point size using the `plot_kws` argument.  Set it using the dictionary: `{\"s\": 15}`.\n",
    "\n",
    "Hint: \n",
    "- Use the `qual_cols` argument to only include the list of columns you want to plot.\n",
    "- Use the `sample` function to limit the number of points.\n",
    "\n",
    "The plot will be huge! You can view it in the notebook but it will be difficult to read the labels. Therefore, save the figure to a file named `covtype.pairplot.png` for viewing. It will take a few minutes to display the plot.\n",
    "\n",
    "(5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5h.** Explain why it is important to examine the pairwise scatterplots of all quantitative columns  (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5i.** Create 10 figures such that each figure corresponds to a single quantitative column in the data.  Each figure should contain 7 boxplots, one for each cover type, and should have a title indicating the quantitative column it describes. Save each figure using the naming scheme: `covtype-{column_name}.boxplot.png`. Replace the tag `{column_name}` with the name of the column represented by the figure.  Exclude outliers from the plots.\n",
    "\n",
    "Hints: \n",
    "1. First, group the dataframe by `Cover_type`\n",
    "2. Second, loop over all the names of quantitative columns.\n",
    "3. Third, you can create a boxplot using the dataframe summary statistics:\n",
    "   ```python\n",
    "   # Create a boxplot using the descriptive summary of the data and the built-in plot function\n",
    "   # of dataframes.\n",
    "   df.describe().transpose().plot(kind=\"box\", title=\"my plot\", showfliers=False, rot=90);\n",
    "   ```\n",
    "4. Because you will use the `DataFrame.plot` function you aren't calling matplotlib or Seaborn functions directly.  Therefore, use the `plt.savefig` function to save each plot. Remember, the `plt` object always maintains the current figure, so you can use it to call the `savefig` function.\n",
    "5. Do not limit the numer of rows as in the pairplot.\n",
    "\n",
    "(8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5j.** Explain why it is important to review the distribution of the \"Cover_Type\" column with every other quantitative data column (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Check for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5k.** Identify if any quantitative columns have outliers. Do this by generating a **single** figure containing one boxplot for each quantitative column (excluding the 40 binary soil type columns). Save the figure as `covtype-outlier_check.png`. Unlike the previous 10 figures you do not need to create separate boxplots by cover type (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5l.** Explain why it is important to look for outliers prior to using machine learning techniques (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Make assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6a.** Explain which columns of data would be poor predictors of cover type. Justify your answer by referring to the plots from Section 5 (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6b.** Write which columns you expect can contribute to prediction of cover type? (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Perform Supervised Machine Learning\n",
    "### 7.1 Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7a.** Create a subset of the original data that contains only the columns you indicated in task 6b and the `Cover_Type` column.  Print the list of remaining columns to verify the dataframe has the columns you want to keep:\n",
    "\n",
    "Hint:\n",
    "- Drop all column from the dataset not deemed predictive.\n",
    "\n",
    "(3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7b.** For machine learning we need to separate the column containing our dependent variable `Cover_Type` from the independent variables.  Create a Numpy array containing the dependent variable `Cover_Type`. Name it `Y` (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7c.** Create a 2D numpy array containing only the independent variables (i.e. all of the predictive columns). Name it `X` (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Normalize the data\n",
    "Many machine learning algorithms expect that the quantitative columns have a mean centered at 0 with data points scaled to unit variance.  See the [preprocessing documentation](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler) for Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7d**.  Normalize the `X` dataframe using the [preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale) or [preprocessing.robust_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.robust_scale.html#sklearn.preprocessing.robust_scale) function of Sklearn. Choose the method most appropriate given the state of outliers in the data. (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Split the data for testing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7e.** Use Sklearn to create a testing model by dividing the two numpy arrays into two groups, one with 80%, which will be used for training the models, and one with 20%, which will be used for validating the models.  A random seed is required. Use a seed  of `7`.  Name your trainig sets `Xt` and `Yt` and the validation sets `Xv` and `Yv` respectively (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7f.** We want to perform a 10-fold cross-validation scheme to estimate accuracy.  This will split our training dataset into 10 pieces, train on 9, test on 1 and repeat for all combinations.  Create a KFold model object for use later when running the machine learning alogrithms. Use a random state seed of `7`.  Name the KFold object `kfold` (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Evaulate ML approaches\n",
    "Using the training data created in task 7e and the KFold model created in task 7f, we will now execute a variety of ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7g**. First, we want to store the results of all ML algorithms that we'll be using. Remember we'll be performing  a 10-fold cross-validation scheme so this will yield 10 results for each algorithm.   You will store the results of each ML algorithm into its approriate element of the dictionary.  Execute the following code to initialize a python dictionary where results will be stored.\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    'LogisticRegression' : np.zeros(10),\n",
    "    'LinearDiscriminantAnalysis' : np.zeros(10),\n",
    "    'KNeighborsClassifier' : np.zeros(10),\n",
    "    'DecisionTreeClassifier' : np.zeros(10),\n",
    "    'GaussianNB' : np.zeros(10),\n",
    "    'SVC' : np.zeros(10)\n",
    "}\n",
    "```\n",
    "(3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7h.** Create two variables. One named `scoring` and the other `error_score`.  Set the value of `scoring` to `\"accuracy\"` and the `error_score` to `np.nan`. You will use these two variables for model section of every ML method below (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7i.** Execute the `LogisticRegression` algorithm and save the results in the `results` dictionary.  Use the following arguments:  `solver` as `\"lbfgs\"` and  `multi_class` as `\"auto\"` (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7j.** Execute the `KNeighborsClassifier` algorithm and save the results in the `results` dictionary (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7k.** Execute the `LinearDiscriminantAnalysis` algorithm and save the results in the `results` dictionary (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7l.** Execute the `DecisionTreeClassifier` algorithm and save the results in the `results` dictionary (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7m.** Execute the `GaussianNB` algorithm and save the results in the `results` dictionary (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7n.** Execute the `SVC` algorithm and save the results in the `results` dictionary. Use `auto` as the the `gamma` arument (3 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7o.** Create a figure of boxplots that shows the distribution of results from each method. Save the figure using the name `covtype.ML_results.png` (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7p.** Write which algorithm you feel performed the best and explain (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Make Predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7q.** Using the algorithm that performs the best, use it to make a prediction using the `Xv` validation we set aside earlier (4 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7r**.  Show the accuracy score of the prediction (4 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7s** Show the confusion matrix.  Be sure to use the `print` function to ensure printing in the notebook looks good (4 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7t.** Print the classifcation report. Be sure to use the `print` function to ensure printing in the notebook looks good (4 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8a**.  Explain in your own words the meaning of the results in last three cells of Section 7. How well did the algorithm perform? (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8b.** Write if there anything you would do differently to try to improve the quality of the prediction (3 pts)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
